{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9351312,"sourceType":"datasetVersion","datasetId":5511875}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["## setting"],"metadata":{"id":"vFz9SUhJMpWX"}},{"cell_type":"code","source":["import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"],"metadata":{"id":"w9xPlS6Jzfnb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install datasets==2.14.0"],"metadata":{"id":"9Jv2WkMSXYa9","execution":{"iopub.status.busy":"2024-09-25T03:37:59.441800Z","iopub.execute_input":"2024-09-25T03:37:59.442413Z","iopub.status.idle":"2024-09-25T03:38:13.618390Z","shell.execute_reply.started":"2024-09-25T03:37:59.442367Z","shell.execute_reply":"2024-09-25T03:38:13.617303Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import numpy as np\n","import random"],"metadata":{"id":"BxufniJiMuHb","execution":{"iopub.status.busy":"2024-09-25T03:38:13.619876Z","iopub.execute_input":"2024-09-25T03:38:13.620195Z","iopub.status.idle":"2024-09-25T03:38:13.983616Z","shell.execute_reply.started":"2024-09-25T03:38:13.620161Z","shell.execute_reply":"2024-09-25T03:38:13.982834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import torch\n","import time\n","from tqdm import tqdm\n","from torch.optim import AdamW\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import FunnelTokenizer, FunnelForSequenceClassification, AdamW, get_linear_schedule_with_warmup, TrainingArguments, Trainer, DataCollatorWithPadding\n","from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"7bNaqsEEMuVe","execution":{"iopub.status.busy":"2024-09-25T03:38:13.986116Z","iopub.execute_input":"2024-09-25T03:38:13.986594Z","iopub.status.idle":"2024-09-25T03:38:32.523141Z","shell.execute_reply.started":"2024-09-25T03:38:13.986550Z","shell.execute_reply":"2024-09-25T03:38:32.522332Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Seed 설정\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","\n","seed = 0\n","set_seed(seed)"],"metadata":{"id":"KR4hojw-c6_o","execution":{"iopub.status.busy":"2024-09-25T03:38:32.524368Z","iopub.execute_input":"2024-09-25T03:38:32.525125Z","iopub.status.idle":"2024-09-25T03:38:32.535549Z","shell.execute_reply.started":"2024-09-25T03:38:32.525080Z","shell.execute_reply":"2024-09-25T03:38:32.534549Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## data"],"metadata":{"id":"K5Bis26xNKEk"}},{"cell_type":"code","source":["path = '/kaggle/input/'\n","sample_SEED = 0"],"metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:38:32.536875Z","iopub.execute_input":"2024-09-25T03:38:32.537601Z","iopub.status.idle":"2024-09-25T03:38:32.557648Z","shell.execute_reply.started":"2024-09-25T03:38:32.537554Z","shell.execute_reply":"2024-09-25T03:38:32.556912Z"},"trusted":true,"id":"600NdLZpzZHY"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["data = pd.read_json(path+'data.json')\n","\n","def split_data(data, sample_SEED, fixSEED=0):\n","  # normal bot split\n","  normal = data[data['restrict']==0].reset_index(drop=True)\n","  bot = data[data['restrict']==1].reset_index(drop=True)\n","  # normal underampling\n","  random.seed(sample_SEED)\n","  sample = random.sample(list(range(len(normal))), len(bot))\n","  normal = normal.loc[sample].reset_index(drop=True)\n","  data = pd.concat([normal, bot], axis=0)\n","  data['restrict'].value_counts()\n","  # train valid test split\n","  train, test = train_test_split(data, test_size=0.3, random_state=fixSEED, stratify = data['restrict'])\n","  train, valid = train_test_split(train, test_size=0.3, random_state=fixSEED, stratify = train['restrict'])\n","  train = train.reset_index(drop=True)\n","  valid = valid.reset_index(drop=True)\n","  test = test.reset_index(drop=True)\n","  # 1:1 fix\n","  random.seed(fixSEED)\n","  move = random.sample(list(valid[valid['restrict']==1].index), 1)\n","  test = pd.concat([test, valid.loc[move]], axis=0).reset_index(drop=True)\n","  valid = valid.drop(move, axis=0).reset_index(drop=True)\n","  return train, valid, test\n","\n","# data split\n","train, valid, test = split_data(data, sample_SEED)"],"metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:38:32.558885Z","iopub.execute_input":"2024-09-25T03:38:32.559164Z","iopub.status.idle":"2024-09-25T03:38:34.651341Z","shell.execute_reply.started":"2024-09-25T03:38:32.559133Z","shell.execute_reply":"2024-09-25T03:38:34.650572Z"},"trusted":true,"id":"KZv7hDF3zZHY"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## model setting"],"metadata":{"id":"wnr0LK2zSAap"}},{"cell_type":"code","source":["# model, tokenizer\n","tokenizer = FunnelTokenizer.from_pretrained(\"funnel-transformer/small-base\")\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","model = FunnelForSequenceClassification.from_pretrained(\"funnel-transformer/small-base\", num_labels=2)\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"],"metadata":{"id":"bK6h8KmqOl-r","execution":{"iopub.status.busy":"2024-09-25T03:38:34.653190Z","iopub.execute_input":"2024-09-25T03:38:34.653573Z","iopub.status.idle":"2024-09-25T03:38:37.654315Z","shell.execute_reply.started":"2024-09-25T03:38:34.653531Z","shell.execute_reply":"2024-09-25T03:38:37.653345Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["CUDA_LAUNCH_BLOCKING=1"],"metadata":{"id":"3FqbK1vvRj2F","execution":{"iopub.status.busy":"2024-09-25T03:38:37.655337Z","iopub.execute_input":"2024-09-25T03:38:37.655622Z","iopub.status.idle":"2024-09-25T03:38:37.663561Z","shell.execute_reply.started":"2024-09-25T03:38:37.655592Z","shell.execute_reply":"2024-09-25T03:38:37.662411Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## text"],"metadata":{"id":"2PCp0NwGzZHa"}},{"cell_type":"code","source":["from datasets import Dataset, DatasetDict\n","\n","# Tokenization function\n","def tokenize_function(examples):\n","    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=1024)\n","\n","# 전처리 함수\n","def prepare_data(df):\n","    data = {'text': df['text'].tolist(), 'restrict': df['restrict'].tolist()}\n","    dataset = Dataset.from_dict(data)\n","    dataset = dataset.map(tokenize_function, batched=True)\n","    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'restrict'])\n","    return dataset\n","\n","# X, y 분리\n","X_train, y_train = train['text'], train['restrict']\n","X_val, y_val = valid['text'], valid['restrict']\n","X_test, y_test = test['text'], test['restrict']\n","\n","\n","train_df = pd.DataFrame(X_train)\n","train_df['restrict'] = y_train\n","val_df = pd.DataFrame(X_val)\n","val_df['restrict'] = y_val\n","test_df = pd.DataFrame(X_test)\n","test_df['restrict'] = y_test\n","\n","train_dataset = prepare_data(train_df)\n","val_dataset = prepare_data(val_df)\n","test_dataset = prepare_data(test_df)"],"metadata":{"id":"axzUzwgnOqj-","execution":{"iopub.status.busy":"2024-09-25T03:38:37.666933Z","iopub.execute_input":"2024-09-25T03:38:37.667532Z","iopub.status.idle":"2024-09-25T03:40:39.309852Z","shell.execute_reply.started":"2024-09-25T03:38:37.667500Z","shell.execute_reply":"2024-09-25T03:40:39.308932Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# batch size = 4\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=4)\n","test_loader = DataLoader(test_dataset, batch_size=4)\n","\n","# Optimizer\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","num_epochs = 3\n","\n","# Learning rate scheduler -> 학습률을 줄이거나 늘리면서 안정성+성능 개선 가능\n","num_training_steps = num_epochs * len(train_loader)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","# Accumulate gradients over\n","gradient_accumulation_steps = 4\n","\n","# Training function\n","def train(model, train_loader, optimizer, scheduler):\n","    model.train()\n","    total_loss = 0\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    for step, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n","        with torch.cuda.amp.autocast():\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['restrict'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss / gradient_accumulation_steps\n","            total_loss += loss.item()\n","\n","        scaler.scale(loss).backward()\n","\n","        if (step + 1) % gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","\n","    return total_loss / len(train_loader)\n","\n","# Evaluation function\n","def evaluate(model, data_loader):\n","    model.eval()\n","    preds, true_labels = [], []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['restrict'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            preds.extend(torch.argmax(logits, axis=1).cpu().numpy())\n","            true_labels.extend(labels.cpu().numpy())\n","\n","    return preds, true_labels\n","\n","# 훈련 시간 측정 시작\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    epoch_start_time = time.time()\n","    train_loss = train(model, train_loader, optimizer, scheduler)\n","    epoch_end_time = time.time()\n","\n","    print(f\"Epoch {epoch + 1}, Loss: {train_loss}\")\n","    print(f\"Epoch {epoch + 1} Computing Time: {epoch_end_time - epoch_start_time:} seconds\")\n","\n","    # validation data 평가\n","    predicted_labels, true_labels = evaluate(model, val_loader)\n","    f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n","    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n","    recall = recall_score(true_labels, predicted_labels, zero_division=1)\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","    print(f\"Epoch {epoch + 1}, Validation F1 Score: {f1:}\")\n","    print(f\"Validation Precision: {precision:}\")\n","    print(f\"Validation Recall: {recall:}\")\n","    print(f\"Validation Accuracy: {accuracy:}\")\n","    print(\"Validation Confusion Matrix:\\n\", conf_matrix)\n","\n","# 훈련 시간 측정 종료\n","end_time = time.time()\n","total_training_time = end_time - start_time # 훈련시간\n","\n","# Final prediction\n","predicted_labels, true_labels = evaluate(model, test_loader)\n","f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n","precision = precision_score(true_labels, predicted_labels, zero_division=1)\n","recall = recall_score(true_labels, predicted_labels, zero_division=1)\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","print(\"Final Test Results:\")\n","print(f\"Test F1 Score: {f1:}\")\n","print(f\"Test Precision: {precision:}\")\n","print(f\"Test Recall: {recall:}\")\n","print(f\"Test Accuracy: {accuracy:}\")\n","print(\"Test Confusion Matrix:\\n\", conf_matrix)\n","print(f\"Total Computing Time: {total_training_time:} seconds\")"],"metadata":{"id":"7kcHjfDFLgjr","execution":{"iopub.status.busy":"2024-09-25T03:40:39.311455Z","iopub.execute_input":"2024-09-25T03:40:39.311809Z","iopub.status.idle":"2024-09-25T03:55:10.013965Z","shell.execute_reply.started":"2024-09-25T03:40:39.311774Z","shell.execute_reply":"2024-09-25T03:55:10.013042Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## longtext"],"metadata":{"id":"Q8T3DQQfN7JE","executionInfo":{"status":"ok","timestamp":1722951570343,"user_tz":-540,"elapsed":30039,"user":{"displayName":"민지현","userId":"11188200291596538384"}},"outputId":"62aadec5-8e7a-475e-cc15-900cc37f32b1"}},{"cell_type":"code","source":["data = pd.read_json(path+'data.json')\n","\n","# data split\n","train, valid, test = split_data(data, sample_SEED)\n","\n","seed = 0\n","set_seed(seed)\n","\n","# model, tokenizer\n","tokenizer = FunnelTokenizer.from_pretrained(\"funnel-transformer/small-base\")\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","model = FunnelForSequenceClassification.from_pretrained(\"funnel-transformer/small-base\", num_labels=2)\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"],"metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:55:10.015150Z","iopub.execute_input":"2024-09-25T03:55:10.015461Z","iopub.status.idle":"2024-09-25T03:55:11.279555Z","shell.execute_reply.started":"2024-09-25T03:55:10.015419Z","shell.execute_reply":"2024-09-25T03:55:11.278645Z"},"trusted":true,"id":"RnR-Ai3EzZHb"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from datasets import Dataset, DatasetDict\n","\n","# Tokenization function\n","def tokenize_function(examples):\n","    return tokenizer(examples['longtext'], padding='max_length', truncation=True, max_length=512)\n","\n","# 전처리 함수\n","def prepare_data(df):\n","    data = {'longtext': df['longtext'].tolist(), 'restrict': df['restrict'].tolist()}\n","    dataset = Dataset.from_dict(data)\n","    dataset = dataset.map(tokenize_function, batched=True)\n","    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'restrict'])\n","    return dataset\n","\n","# X, y 분리\n","X_train, y_train = train['longtext'], train['restrict']\n","X_val, y_val = valid['longtext'], valid['restrict']\n","X_test, y_test = test['longtext'], test['restrict']\n","\n","\n","train_df = pd.DataFrame(X_train)\n","train_df['restrict'] = y_train\n","val_df = pd.DataFrame(X_val)\n","val_df['restrict'] = y_val\n","test_df = pd.DataFrame(X_test)\n","test_df['restrict'] = y_test\n","\n","train_dataset = prepare_data(train_df)\n","val_dataset = prepare_data(val_df)\n","test_dataset = prepare_data(test_df)"],"metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:55:11.280726Z","iopub.execute_input":"2024-09-25T03:55:11.281109Z","iopub.status.idle":"2024-09-25T03:57:17.414216Z","shell.execute_reply.started":"2024-09-25T03:55:11.281072Z","shell.execute_reply":"2024-09-25T03:57:17.413162Z"},"trusted":true,"colab":{"referenced_widgets":["e707eeb315544e5b83a5095ff1c1ec3c","3f33523eaf944bb3a159364deb4e7ac0","aa5620b72ca9408b809d4bfa8399b564"]},"id":"J_IYlY09zZHb","outputId":"7cf6b9c0-4ad6-419d-bfde-5b3c21eb74a4"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5642 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e707eeb315544e5b83a5095ff1c1ec3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2418 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f33523eaf944bb3a159364deb4e7ac0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3456 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa5620b72ca9408b809d4bfa8399b564"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["# batch size = 4\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=4)\n","test_loader = DataLoader(test_dataset, batch_size=4)\n","\n","# Optimizer\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","num_epochs = 3\n","\n","# Learning rate scheduler -> 학습률을 줄이거나 늘리면서 안정성+성능 개선 가능\n","num_training_steps = num_epochs * len(train_loader)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","# Accumulate gradients over\n","gradient_accumulation_steps = 4\n","\n","# Training function\n","def train(model, train_loader, optimizer, scheduler):\n","    model.train()\n","    total_loss = 0\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    for step, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n","        with torch.cuda.amp.autocast():\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['restrict'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss / gradient_accumulation_steps\n","            total_loss += loss.item()\n","\n","        scaler.scale(loss).backward()\n","\n","        if (step + 1) % gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","\n","    return total_loss / len(train_loader)\n","\n","# Evaluation function\n","def evaluate(model, data_loader):\n","    model.eval()\n","    preds, true_labels = [], []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['restrict'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            preds.extend(torch.argmax(logits, axis=1).cpu().numpy())\n","            true_labels.extend(labels.cpu().numpy())\n","\n","    return preds, true_labels\n","\n","# 훈련 시간 측정 시작\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    epoch_start_time = time.time()\n","    train_loss = train(model, train_loader, optimizer, scheduler)\n","    epoch_end_time = time.time()\n","\n","    print(f\"Epoch {epoch + 1}, Loss: {train_loss}\")\n","    print(f\"Epoch {epoch + 1} Computing Time: {epoch_end_time - epoch_start_time:} seconds\")\n","\n","    # validation data 평가\n","    predicted_labels, true_labels = evaluate(model, val_loader)\n","    f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n","    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n","    recall = recall_score(true_labels, predicted_labels, zero_division=1)\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","    print(f\"Epoch {epoch + 1}, Validation F1 Score: {f1:}\")\n","    print(f\"Validation Precision: {precision:}\")\n","    print(f\"Validation Recall: {recall:}\")\n","    print(f\"Validation Accuracy: {accuracy:}\")\n","    print(\"Validation Confusion Matrix:\\n\", conf_matrix)\n","\n","# 훈련 시간 측정 종료\n","end_time = time.time()\n","total_training_time = end_time - start_time # 훈련시간\n","\n","# Final prediction\n","predicted_labels, true_labels = evaluate(model, test_loader)\n","f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n","precision = precision_score(true_labels, predicted_labels, zero_division=1)\n","recall = recall_score(true_labels, predicted_labels, zero_division=1)\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","print(\"Final Test Results:\")\n","print(f\"Test F1 Score: {f1:}\")\n","print(f\"Test Precision: {precision:}\")\n","print(f\"Test Recall: {recall:}\")\n","print(f\"Test Accuracy: {accuracy:}\")\n","print(\"Test Confusion Matrix:\\n\", conf_matrix)\n","print(f\"Total Computing Time: {total_training_time:} seconds\")"],"metadata":{"execution":{"iopub.status.busy":"2024-09-25T03:57:17.416232Z","iopub.execute_input":"2024-09-25T03:57:17.416710Z","iopub.status.idle":"2024-09-25T04:11:47.636845Z","shell.execute_reply.started":"2024-09-25T03:57:17.416627Z","shell.execute_reply":"2024-09-25T04:11:47.635597Z"},"trusted":true,"id":"oBOAzqhWzZHb"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["## longlongtext"],"metadata":{"id":"1pPzVtF-zZHc"}},{"cell_type":"code","source":["data = pd.read_json(path+'data.json')\n","\n","# data split\n","train, valid, test = split_data(data, sample_SEED)\n","\n","seed = 0\n","set_seed(seed)\n","\n","# model, tokenizer\n","tokenizer = FunnelTokenizer.from_pretrained(\"funnel-transformer/small-base\")\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","model = FunnelForSequenceClassification.from_pretrained(\"funnel-transformer/small-base\", num_labels=2)\n","\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"],"metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:11:47.638269Z","iopub.execute_input":"2024-09-25T04:11:47.638770Z","iopub.status.idle":"2024-09-25T04:11:48.866322Z","shell.execute_reply.started":"2024-09-25T04:11:47.638720Z","shell.execute_reply":"2024-09-25T04:11:48.865367Z"},"trusted":true,"id":"1rzGzj44zZHc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from datasets import Dataset, DatasetDict\n","\n","# Tokenization function\n","def tokenize_function(examples):\n","    return tokenizer(examples['longlongtext'], padding='max_length', truncation=True, max_length=512)\n","\n","# 전처리 함수\n","def prepare_data(df):\n","    data = {'longlongtext': df['longlongtext'].tolist(), 'restrict': df['restrict'].tolist()}\n","    dataset = Dataset.from_dict(data)\n","    dataset = dataset.map(tokenize_function, batched=True)\n","    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'restrict'])\n","    return dataset\n","\n","# X, y 분리\n","X_train, y_train = train['longlongtext'], train['restrict']\n","X_val, y_val = valid['longlongtext'], valid['restrict']\n","X_test, y_test = test['longlongtext'], test['restrict']\n","\n","\n","train_df = pd.DataFrame(X_train)\n","train_df['restrict'] = y_train\n","val_df = pd.DataFrame(X_val)\n","val_df['restrict'] = y_val\n","test_df = pd.DataFrame(X_test)\n","test_df['restrict'] = y_test\n","\n","train_dataset = prepare_data(train_df)\n","val_dataset = prepare_data(val_df)\n","test_dataset = prepare_data(test_df)"],"metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:11:48.867808Z","iopub.execute_input":"2024-09-25T04:11:48.868190Z","iopub.status.idle":"2024-09-25T04:13:58.715081Z","shell.execute_reply.started":"2024-09-25T04:11:48.868148Z","shell.execute_reply":"2024-09-25T04:13:58.714224Z"},"trusted":true,"colab":{"referenced_widgets":["80d76f1fdf7342ad87df381ae0c7c68b","7cce7d09c42545ca82370af42ec94784","af249a6a73d747b18e46439d34eebf99"]},"id":"5lfdZEbNzZHd","outputId":"705b0e0b-7a5b-41a2-f5ed-f79fc1354b17"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5642 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80d76f1fdf7342ad87df381ae0c7c68b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2418 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cce7d09c42545ca82370af42ec94784"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3456 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af249a6a73d747b18e46439d34eebf99"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":["# batch size = 4\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=4)\n","test_loader = DataLoader(test_dataset, batch_size=4)\n","\n","# Optimizer\n","optimizer = AdamW(model.parameters(), lr=2e-5)\n","num_epochs = 3\n","\n","# Learning rate scheduler -> 학습률을 줄이거나 늘리면서 안정성+성능 개선 가능\n","num_training_steps = num_epochs * len(train_loader)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","# Accumulate gradients over\n","gradient_accumulation_steps = 4\n","\n","# Training function\n","def train(model, train_loader, optimizer, scheduler):\n","    model.train()\n","    total_loss = 0\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    for step, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n","        with torch.cuda.amp.autocast():\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['restrict'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss / gradient_accumulation_steps\n","            total_loss += loss.item()\n","\n","        scaler.scale(loss).backward()\n","\n","        if (step + 1) % gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            scheduler.step()\n","            optimizer.zero_grad()\n","\n","    return total_loss / len(train_loader)\n","\n","# Evaluation function\n","def evaluate(model, data_loader):\n","    model.eval()\n","    preds, true_labels = [], []\n","\n","    with torch.no_grad():\n","        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['restrict'].to(device)\n","\n","            outputs = model(input_ids, attention_mask=attention_mask)\n","            logits = outputs.logits\n","            preds.extend(torch.argmax(logits, axis=1).cpu().numpy())\n","            true_labels.extend(labels.cpu().numpy())\n","\n","    return preds, true_labels\n","\n","# 훈련 시간 측정 시작\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    epoch_start_time = time.time()\n","    train_loss = train(model, train_loader, optimizer, scheduler)\n","    epoch_end_time = time.time()\n","\n","    print(f\"Epoch {epoch + 1}, Loss: {train_loss}\")\n","    print(f\"Epoch {epoch + 1} Computing Time: {epoch_end_time - epoch_start_time:} seconds\")\n","\n","    # validation data 평가\n","    predicted_labels, true_labels = evaluate(model, val_loader)\n","    f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n","    precision = precision_score(true_labels, predicted_labels, zero_division=1)\n","    recall = recall_score(true_labels, predicted_labels, zero_division=1)\n","    accuracy = accuracy_score(true_labels, predicted_labels)\n","    conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","    print(f\"Epoch {epoch + 1}, Validation F1 Score: {f1:}\")\n","    print(f\"Validation Precision: {precision:}\")\n","    print(f\"Validation Recall: {recall:}\")\n","    print(f\"Validation Accuracy: {accuracy:}\")\n","    print(\"Validation Confusion Matrix:\\n\", conf_matrix)\n","\n","# 훈련 시간 측정 종료\n","end_time = time.time()\n","total_training_time = end_time - start_time # 훈련시간\n","\n","# Final prediction\n","predicted_labels, true_labels = evaluate(model, test_loader)\n","f1 = f1_score(true_labels, predicted_labels, zero_division=1)\n","precision = precision_score(true_labels, predicted_labels, zero_division=1)\n","recall = recall_score(true_labels, predicted_labels, zero_division=1)\n","accuracy = accuracy_score(true_labels, predicted_labels)\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","print(\"Final Test Results:\")\n","print(f\"Test F1 Score: {f1:}\")\n","print(f\"Test Precision: {precision:}\")\n","print(f\"Test Recall: {recall:}\")\n","print(f\"Test Accuracy: {accuracy:}\")\n","print(\"Test Confusion Matrix:\\n\", conf_matrix)\n","print(f\"Total Computing Time: {total_training_time:} seconds\")"],"metadata":{"execution":{"iopub.status.busy":"2024-09-25T04:13:58.716420Z","iopub.execute_input":"2024-09-25T04:13:58.717089Z","iopub.status.idle":"2024-09-25T04:28:28.697230Z","shell.execute_reply.started":"2024-09-25T04:13:58.717037Z","shell.execute_reply":"2024-09-25T04:28:28.696274Z"},"trusted":true,"id":"hLQJhVPCzZHd"},"outputs":[],"execution_count":null}]}